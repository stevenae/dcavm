{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3Qx3BEtHObYkuDoO4FpaD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevenae/dcavm/blob/main/dc_avm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH9zAxCWcn2S"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import xgboost as xgb\n",
        "\n",
        "resi_fn = '~/Downloads/Computer_Assisted_Mass_Appraisal_-_Residential.csv'\n",
        "dat = pl.read_csv(resi_fn)\n",
        "condo_fn = '~/Downloads/Computer_Assisted_Mass_Appraisal_-_Condominium.csv'\n",
        "condo = pl.read_csv(condo_fn)\n",
        "condo = condo.rename({'LIVING_GBA':'GBA'})\n",
        "gis_fn = '~/Downloads/Address_Points.csv'\n",
        "gis = pl.read_csv(gis_fn,\n",
        "    columns=['LATITUDE','LONGITUDE','SSL','ADDRESS','RESIDENTIAL_TYPE'])\n",
        "address_fn = '~/Downloads/Address_Residential_Units.csv'\n",
        "address_residential_units = pl.read_csv(address_fn,\n",
        "     columns=['PRIMARY_ADDRESS','CONDO_SSL','FULL_ADDRESS'])\n",
        "\n",
        "condo = condo.join(address_residential_units,left_on='SSL',right_on='CONDO_SSL')\n",
        "condo = condo.join(gis,left_on='PRIMARY_ADDRESS',right_on='ADDRESS')\n",
        "\n",
        "condo = condo.filter(pl.col('RESIDENTIAL_TYPE')=='RESIDENTIAL')\n",
        "dat = dat.filter(pl.col('QUALIFIED')=='Q')\n",
        "condo = condo.filter(pl.col('QUALIFIED')=='Q')\n",
        "\n",
        "dat = dat.join(gis,on='SSL')\n",
        "\n",
        "condo = condo.rename({'FULL_ADDRESS':'ADDRESS'})\n",
        "condo = condo.select(pl.col(set(condo.columns) & set(dat.columns)))\n",
        "dat = pl.concat([dat,condo], how='diagonal_relaxed')\n",
        "\n",
        "dat = dat.filter(pl.col('PRICE')>1e5)\n",
        "dat = dat.filter(pl.col('PRICE')<2e6)\n",
        "dat = dat.with_columns(\n",
        "    pl.col('EYB').replace(0,None),\n",
        "    pl.col('AYB').replace(0,None)\n",
        ")\n",
        "\n",
        "dat = dat.with_columns(\n",
        "   pl.col(\"SALEDATE\").str.to_date(\"%Y/%m/%d %H:%M:%S+00\")\n",
        ")\n",
        "\n",
        "dat = dat.with_columns(\n",
        "   pl.col(\"AC\")=='Y'\n",
        ")\n",
        "\n",
        "xgb_data = dat.select(pl.col(['LATITUDE','LONGITUDE',\n",
        "           'BATHRM','HF_BATHRM','HEAT','AC','ROOMS',\n",
        "                        'BEDRM','AYB','YR_RMDL','EYB','STORIES','GBA',\n",
        "                        'GRADE','CNDTN','EXTWALL','ROOF','INTWALL',\n",
        "                        'KITCHENS','FIREPLACES','LANDAREA',\n",
        "                        'SALEDATE',\n",
        "                        'NUM_UNITS','USECODE',\n",
        "                        'PRICE']))\n",
        "\n",
        "categories = ['HEAT','ROOF','EXTWALL','INTWALL','AC','USECODE']\n",
        "dummies = xgb_data.select(pl.col(categories)).to_dummies(drop_first=True)\n",
        "xgb_data = xgb_data.select(pl.col(set(xgb_data.columns) - set(categories)))\n",
        "xgb_data = pl.concat([xgb_data,dummies],how='horizontal')\n",
        "xgb_err = pl.DataFrame()\n",
        "models = []\n",
        "for iteration in range(1,10):\n",
        "    # Date filtering for train/test\n",
        "\n",
        "    saledate_min = pl.col('SALEDATE').min()\n",
        "    saledate_max = pl.col('SALEDATE').max()\n",
        "\n",
        "    iter_train_end_offset_str = '-%dmo' % iteration\n",
        "    iter_train_end_offset = saledate_max.dt.offset_by(iter_train_end_offset_str)\n",
        "\n",
        "    iter_test_end_offset_str = '-%dmo' % (iteration - 1)\n",
        "    iter_test_end_offset = saledate_max.dt.offset_by(iter_test_end_offset_str)\n",
        "\n",
        "    train_filter = pl.col('SALEDATE').is_between(saledate_min,\n",
        "                                                 iter_train_end_offset)\n",
        "    test_filter = pl.col('SALEDATE').is_between(iter_train_end_offset,\n",
        "                                                iter_test_end_offset)\n",
        "\n",
        "    train_data = xgb_data.filter(train_filter)\n",
        "    train_label = train_data.select('PRICE')\n",
        "    train_data = train_data.drop('PRICE')\n",
        "\n",
        "    test_data = xgb_data.filter(test_filter)\n",
        "    test_label = test_data.select('PRICE')\n",
        "    test_data = test_data.drop('PRICE')\n",
        "\n",
        "    # Debug vars\n",
        "\n",
        "    train_date_min_debug = train_data.select('SALEDATE').min().to_numpy()[0][0]\n",
        "    train_date_max_debug = train_data.select('SALEDATE').max().to_numpy()[0][0]\n",
        "    test_date_min_debug = test_data.select('SALEDATE').min().to_numpy()[0][0]\n",
        "    test_date_max_debug = test_data.select('SALEDATE').max().to_numpy()[0][0]\n",
        "\n",
        "    print('iter {}'.format(iteration))\n",
        "    print('train {} to {}'.format(train_date_min_debug,train_date_max_debug))\n",
        "    print('test {} to {}'.format(test_date_min_debug,test_date_max_debug))\n",
        "    print('%d tr obs, %d va obs' % (len(train_label), len(test_label)))\n",
        "\n",
        "    dtrain = xgb.DMatrix(train_data, label = train_label)\n",
        "    dtest = xgb.DMatrix(test_data, label = test_label)\n",
        "    evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "    param = {'max_depth': 10, 'eta': .01, 'objective': 'reg:tweedie',\n",
        "        'eval_metric':'mape', 'tree_method':'hist', 'grow_policy':'lossguide'}\n",
        "    num_round = 10000\n",
        "    bst = xgb.train(param, dtrain, num_round, evals=evallist,\n",
        "        early_stopping_rounds=100, verbose_eval=100)\n",
        "\n",
        "    if iteration == 1:\n",
        "        # nowcast predictions and comps\n",
        "        nowcast_data = dat.with_columns(pl.col('SALEDATE')\n",
        "            .max().alias('nowcast_date'))\n",
        "        nowcast_data = nowcast_data.drop('PRICE')\n",
        "        dnow = xgb.DMatrix(xgb_data.drop('PRICE'))\n",
        "        nowcast_predictions = bst.predict(dnow)\n",
        "        nowcast_data = nowcast_data.with_columns(\n",
        "            nowcast_prediction = nowcast_predictions\n",
        "        )\n",
        "        nowcast_data.write_csv('~/Documents/nowcast_predictions.csv',\n",
        "            separator=\",\")\n",
        "\n",
        "    models.append(bst)\n",
        "\n",
        "    predictions = pl.DataFrame({'predictions' : bst.predict(dtest)})\n",
        "    test_data = pl.concat([test_data,predictions,test_label],how='horizontal')\n",
        "    test_data = test_data.with_columns(error =\n",
        "        abs(pl.col('PRICE').sub(pl.col('predictions')))\n",
        "        .truediv(pl.col('PRICE')))\n",
        "    xgb_err = pl.concat([xgb_err,test_data],how='diagonal')\n",
        "\n",
        "xgb_err.write_csv('~/Documents/xgb_errors.csv', separator=\",\")\n"
      ]
    }
  ]
}